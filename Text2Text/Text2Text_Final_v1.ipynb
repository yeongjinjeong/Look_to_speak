{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6790c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import random\n",
    "import warnings\n",
    "import time\n",
    "import math\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "# Unicode warning 제거 (폰트 관련 경고메시지)\n",
    "plt.rcParams['axes.unicode_minus']=False\n",
    "# 한글 폰트 설정\n",
    "plt.rcParams['font.family'] = \"NanumGothic\"\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e660dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#단어 사전 생성\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a1b0012",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordVocab():\n",
    "    def __init__(self):\n",
    "        SOS_TOKEN = 0\n",
    "        EOS_TOKEN = 1\n",
    "        UNKNOWN_TOKEN = 2\n",
    "        \n",
    "        self.unknown_token = UNKNOWN_TOKEN\n",
    "        \n",
    "        # 각 토큰 별 word count\n",
    "        self.word2count = {}\n",
    "        \n",
    "        # word -> idx\n",
    "        self.word2index = {\n",
    "            '<SOS>': SOS_TOKEN, \n",
    "            '<EOS>': EOS_TOKEN,\n",
    "            '<UKN>': UNKNOWN_TOKEN,\n",
    "        }\n",
    "\n",
    "        # idx -> word\n",
    "        self.index2word = {\n",
    "            SOS_TOKEN: '<SOS>', \n",
    "            EOS_TOKEN: '<EOS>', \n",
    "            UNKNOWN_TOKEN: '<UKN>',\n",
    "        }\n",
    "        \n",
    "        # total word counts\n",
    "        self.n_words = 3  # SOS, EOS, UNKNOWN 포함\n",
    "\n",
    "    def add_sentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.add_word(word)\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "    \n",
    "    def word_to_index(self, word):\n",
    "        if word in self.word2index:\n",
    "            return self.word2index[word]\n",
    "        else:\n",
    "            return self.unknown_token\n",
    "    \n",
    "    def index_to_word(self, idx):\n",
    "        return self.index2word[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d41102e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordvocab = WordVocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab43a3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#전처리 프로세스를 클레스화 - 데이터 로드, 전처리, 사전 생성, 시퀀스 변환\n",
    "class QADataset():\n",
    "    def __init__(self, csv_path, min_length=1, max_length=647):\n",
    "        data_dir = 'data'\n",
    "        \n",
    "        # TOKEN 정의\n",
    "        self.SOS_TOKEN = 0 # SOS 토큰\n",
    "        self.EOS_TOKEN = 1 # EOS 토큰\n",
    "        \n",
    "        self.tagger = Okt()   # 형태소 분석기\n",
    "        self.max_length = max_length # 한 문장의 최대 길이 지정\n",
    "        \n",
    "        # CSV 데이터 로드\n",
    "        df = pd.read_csv(csv_path)\n",
    "        \n",
    "        # 한글 정규화\n",
    "        korean_pattern = r'[^ ?,.!A-Za-z0-9가-힣+]'\n",
    "        self.normalizer = re.compile(korean_pattern)\n",
    "        \n",
    "        # src: 질의, tgt: 답변\n",
    "        src_clean = []\n",
    "        tgt_clean = []\n",
    "        \n",
    "        # 단어 사전 생성\n",
    "        wordvocab = WordVocab()\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            src = row['value']\n",
    "            tgt = row['label']\n",
    "            \n",
    "            # 한글 전처리\n",
    "            src = self.clean_text(src)\n",
    "            tgt = self.clean_text(tgt)\n",
    "            \n",
    "            if len(src.split()) > min_length and len(tgt.split()) > min_length:\n",
    "                # 최소 길이를 넘어가는 문장의 단어만 추가\n",
    "                wordvocab.add_sentence(src)\n",
    "                wordvocab.add_sentence(tgt)\n",
    "                src_clean.append(src)\n",
    "                tgt_clean.append(tgt)            \n",
    "        \n",
    "        self.srcs = src_clean\n",
    "        self.tgts = tgt_clean\n",
    "        self.wordvocab = wordvocab\n",
    "        \n",
    "\n",
    "    \n",
    "    def normalize(self, sentence):\n",
    "        # 정규표현식에 따른 한글 정규화\n",
    "        return self.normalizer.sub(\"\", sentence)\n",
    "\n",
    "    def clean_text(self, sentence):\n",
    "        # 한글 정규화\n",
    "        sentence = self.normalize(str(sentence))\n",
    "        # 형태소 처리\n",
    "        sentence = self.tagger.morphs(sentence)\n",
    "        sentence = ' '.join(sentence)\n",
    "        sentence = sentence.lower()\n",
    "        return sentence\n",
    "    \n",
    "    def texts_to_sequences(self, sentence):\n",
    "        # 문장 -> 시퀀스로 변환\n",
    "        sequences = [self.wordvocab.word_to_index(w) for w in sentence.split()]\n",
    "        # 문장 최대 길이 -1 까지 슬라이싱\n",
    "        sequences = sequences[:self.max_length-1]\n",
    "        # 맨 마지막에 EOS TOKEN 추가\n",
    "        sequences.append(self.EOS_TOKEN)\n",
    "        return sequences\n",
    "    \n",
    "    def sequences_to_texts(self, sequences):\n",
    "        # 시퀀스 -> 문장으로 변환\n",
    "        sentences = [self.wordvocab.index_to_word(s.item()) for s in sequences]\n",
    "        return ' '.join(sentences)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        inputs = self.srcs[idx]\n",
    "        inputs_sequences = self.texts_to_sequences(inputs)\n",
    "        \n",
    "        outputs = self.tgts[idx]\n",
    "        outputs_sequences = self.texts_to_sequences(outputs)\n",
    "        \n",
    "        return torch.tensor(inputs_sequences).view(-1, 1), torch.tensor(outputs_sequences).view(-1, 1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.srcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02d13dbf",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m MAX_LENGTH \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m358\u001b[39m\n\u001b[0;32m----> 3\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mQADataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./reduce_df.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMAX_LENGTH\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 32\u001b[0m, in \u001b[0;36mQADataset.__init__\u001b[0;34m(self, csv_path, min_length, max_length)\u001b[0m\n\u001b[1;32m     29\u001b[0m tgt \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# 한글 전처리\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m src \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclean_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m tgt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclean_text(tgt)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(src\u001b[38;5;241m.\u001b[39msplit()) \u001b[38;5;241m>\u001b[39m min_length \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tgt\u001b[38;5;241m.\u001b[39msplit()) \u001b[38;5;241m>\u001b[39m min_length:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m# 최소 길이를 넘어가는 문장의 단어만 추가\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 56\u001b[0m, in \u001b[0;36mQADataset.clean_text\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m     54\u001b[0m sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize(\u001b[38;5;28mstr\u001b[39m(sentence))\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# 형태소 처리\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtagger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmorphs\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m sentence \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(sentence)\n\u001b[1;32m     58\u001b[0m sentence \u001b[38;5;241m=\u001b[39m sentence\u001b[38;5;241m.\u001b[39mlower()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/konlpy/tag/_okt.py:89\u001b[0m, in \u001b[0;36mOkt.morphs\u001b[0;34m(self, phrase, norm, stem)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmorphs\u001b[39m(\u001b[38;5;28mself\u001b[39m, phrase, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, stem\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     87\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Parse phrase to morphemes.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [s \u001b[38;5;28;01mfor\u001b[39;00m s, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mphrase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstem\u001b[49m\u001b[43m)\u001b[49m]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/konlpy/tag/_okt.py:71\u001b[0m, in \u001b[0;36mOkt.pos\u001b[0;34m(self, phrase, norm, stem, join)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"POS tagger.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03mIn contrast to other classes in this subpackage,\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03mthis POS tagger doesn't have a `flatten` option,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;124;03m:param join: If True, returns joined sets of morph and tag.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     69\u001b[0m validate_phrase_inputs(phrase)\n\u001b[0;32m---> 71\u001b[0m tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjki\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mphrase\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjpype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlang\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBoolean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjpype\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjava\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlang\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBoolean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstem\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtoArray()\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m join:\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tokens]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = 358\n",
    "\n",
    "dataset = QADataset('./reduce_df.csv', min_length=1, max_length=MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95b44c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609ae704",
   "metadata": {},
   "source": [
    "Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "982daedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \n",
    "    def __init__(self, d_model, max_len, device):\n",
    "        \"\"\"\n",
    "        sin, cos encoding 구현\n",
    "        \n",
    "        parameter\n",
    "        - d_model : model의 차원\n",
    "        - max_len : 최대 seaquence 길이\n",
    "        - device : cuda or cpu\n",
    "        \"\"\"\n",
    "        \n",
    "        super(PositionalEncoding, self).__init__() # nn.Module 초기화\n",
    "        \n",
    "        # input matrix(자연어 처리에선 임베딩 벡터)와 같은 size의 tensor 생성\n",
    "        # 즉, (max_len, d_model) size\n",
    "        self.encoding = torch.zeros(max_len, d_model, device=device)\n",
    "        self.encoding.requires_grad = False # 인코딩의 그래디언트는 필요 없다. \n",
    "        \n",
    "        # 위치 indexing용 벡터\n",
    "        # pos는 max_len의 index를 의미한다.\n",
    "        pos = torch.arange(0, max_len, device =device)\n",
    "        # 1D : (max_len, ) size -> 2D : (max_len, 1) size -> word의 위치를 반영하기 위해\n",
    "        \n",
    "        pos = pos.float().unsqueeze(dim=1) # int64 -> float32 (없어도 되긴 함)\n",
    "        \n",
    "        # i는 d_model의 index를 의미한다. _2i : (d_model, ) size\n",
    "        # 즉, embedding size가 512일 때, i = [0,512]\n",
    "        _2i = torch.arange(0, d_model, step=2, device=device).float()\n",
    "        \n",
    "        # (max_len, 1) / (d_model/2 ) -> (max_len, d_model/2)\n",
    "        self.encoding[:, ::2] = torch.sin(pos / (10000 ** (_2i / d_model)))\n",
    "        self.encoding[:, 1::2] = torch.cos(pos / (10000 ** (_2i / d_model)))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # self.encoding\n",
    "        # [max_len = 512, d_model = 512]\n",
    "\n",
    "        # batch_size = 128, seq_len = 30\n",
    "        batch_size, seq_len = x.size() \n",
    "        \n",
    "        # [seq_len = 30, d_model = 512]\n",
    "        # [128, 30, 512]의 size를 가지는 token embedding에 더해질 것이다. \n",
    "        # \n",
    "        return self.encoding[:seq_len, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2139e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_vocabs, hidden_size, embedding_dim, num_layers):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        # 단어 사전의 개수 지정\n",
    "        self.pos_encoder = PositionalEncoding(embedding_dim, MAX_LENGTH, device)\n",
    "        self.num_vocabs = num_vocabs\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        \n",
    "        # 임베딩 레이어 정의 (number of vocabs, embedding dimension)\n",
    "        self.embedding = nn.Embedding(num_vocabs, embedding_dim)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(embedding_dim, nhead=8)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=6)\n",
    "       \n",
    "        # GRU (embedding dimension)\n",
    "        self.gru = nn.GRU(embedding_dim, \n",
    "                          hidden_size, \n",
    "                          num_layers=num_layers, \n",
    "                          bidirectional=True, \n",
    "                          batch_first=True,\n",
    "                          dropout=0.2,\n",
    "                         )\n",
    "    def init_weights(self):\n",
    "        torch.nn.init.xavier_uniform_(self.transformer_encoder.weight.data)\n",
    "        torch.nn.init.xavier_uniform_(self.gru.weight.data)\n",
    "        \n",
    "    def forward(self, x, hidden):\n",
    "        print('encoder: x', x.shape)\n",
    "        # (sequence_length, 1)\n",
    "        x = self.embedding(x)\n",
    "        print(\"encoder\", x.shape)\n",
    "        x = self.pos_encoder(x)\n",
    "        x = self.transformer_encoder(x)\n",
    "        output, hidden = self.gru(x, hidden)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self, device):\n",
    "        return torch.zeros(6, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58904405",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_vocabs, hidden_size, embedding_dim, dropout_p=0.2, max_length=MAX_LENGTH):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        self.pos_encoder = PositionalEncoding(embedding_dim, MAX_LENGTH, device)\n",
    "        self.decoder_layer = nn.TransformerDecoderLayer(embedding_dim, nhead=8)\n",
    "        self.transformer_decoder = nn.TransformerDecoder(self.decoder_layer, num_layers=6)\n",
    "\n",
    "        self.embedding = nn.Embedding(num_vocabs, embedding_dim)\n",
    "        self.attn = nn.Linear(hidden_size + embedding_dim, max_length)\n",
    "#         self.attn_combine = nn.Linear(hidden_size*3, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.gru = nn.GRU(embedding_dim,\n",
    "                          hidden_size,\n",
    "                          num_layers=1,\n",
    "                          batch_first=True,\n",
    "                          dropout=dropout_p)\n",
    "        self.out = nn.Linear(hidden_size, num_vocabs)\n",
    "\n",
    "    def init_weights(self):\n",
    "        for i in range(self.gru.num_layers):\n",
    "            torch.nn.init.xavier_uniform_(getattr(self.gru, f'weight_hh_l{i}'))\n",
    "            torch.nn.init.xavier_uniform_(getattr(self.gru, f'weight_ih_l{i}'))\n",
    "\n",
    "    def forward(self, x, hidden, encoder_outputs):\n",
    "        print('decoder: x', x[0].shape)\n",
    "        embedded = self.embedding(x[0]).view(1, 1, -1)\n",
    "        print(\"decoder\", embedded.shape)\n",
    "\n",
    "        x = embedded\n",
    "        x = self.pos_encoder(x)\n",
    "        \n",
    "\n",
    "        # Using last layer of GRU for attention mechanism\n",
    "        hidden_last_layer = hidden[-1].unsqueeze(0)\n",
    "        \n",
    "#         print(embedded.shape, hidden_last_layer.shape)\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden_last_layer), 1)), dim=1)\n",
    "#         attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "#                                  encoder_outputs.unsqueeze(0))\n",
    "\n",
    "#         output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "#         output = self.attn_combine(output).unsqueeze(0)\n",
    "        output = transformer_decoder(x, encoder_outputs)\n",
    "        output = F.relu(output)\n",
    "        hidden = hidden[0].unsqueeze(0)\n",
    "        output, hidden = self.gru(output[0], hidden)\n",
    "        output = F.log_softmax(self.out(output), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(5, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620c0fe9",
   "metadata": {},
   "source": [
    "Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "454496cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionDecoder(nn.Module):\n",
    "    def __init__(self, num_vocabs, hidden_size, embedding_dim, dropout_p=0.2, max_length=MAX_LENGTH):\n",
    "        super(AttentionDecoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(num_vocabs, embedding_dim)\n",
    "        self.attn = nn.Linear(hidden_size + embedding_dim, max_length)\n",
    "        self.attn_combine = nn.Linear(hidden_size*3, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "        self.gru = nn.GRU(hidden_size,\n",
    "                          hidden_size,\n",
    "                          num_layers=1,\n",
    "                          batch_first=True,\n",
    "                          dropout=dropout_p)\n",
    "        self.out = nn.Linear(hidden_size, num_vocabs)\n",
    "\n",
    "    def init_weights(self):\n",
    "        for i in range(self.gru.num_layers):\n",
    "            torch.nn.init.xavier_uniform_(getattr(self.gru, f'weight_hh_l{i}'))\n",
    "            torch.nn.init.xavier_uniform_(getattr(self.gru, f'weight_ih_l{i}'))\n",
    "\n",
    "    def forward(self, x, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(x).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        \n",
    "\n",
    "        # Using last layer of GRU for attention mechanism\n",
    "        hidden_last_layer = hidden[-1].unsqueeze(0)\n",
    "        \n",
    "#         print(embedded.shape, hidden_last_layer.shape)\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden_last_layer), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        hidden = hidden[0].unsqueeze(0)\n",
    "        output, hidden = self.gru(output[0], hidden)\n",
    "        output = F.log_softmax(self.out(output), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(5, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77db84ce",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "972940e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m SOS_TOKEN \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241m.\u001b[39mSOS_TOKEN\n\u001b[1;32m      2\u001b[0m EOS_TOKEN \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mEOS_TOKEN\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "SOS_TOKEN = dataset.SOS_TOKEN\n",
    "EOS_TOKEN = dataset.EOS_TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a183fe58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련시 training loss 를 출력하기 위한 util 함수\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # 주기적인 간격에 이 locator가 tick을 설정\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)\n",
    "    plt.title('Losses over training')\n",
    "    plt.show()\n",
    "    \n",
    "# 훈련시 시간 출력을 위한 util 함수\n",
    "def as_minutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return f'{int(m)}m {int(s)}s'\n",
    "\n",
    "# 훈련시 시간 출력을 위한 util 함수\n",
    "def time_since(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return f'{as_minutes(s)} (remaining: {as_minutes(rs)})'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25171e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, \n",
    "          decoder_optimizer, criterion, device, max_length=MAX_LENGTH, teacher_forcing_ratio=0.5):\n",
    "    \n",
    "    # Encoder의 hidden_state 초기화\n",
    "    encoder_hidden = encoder.init_hidden(device=device)\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    # input_length: 입력 문장의 길이\n",
    "    # target_length: 출력 문장의 길이\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    # Encoder의 출력 결과를 담을 tensor\n",
    "    # (문장의 max_length, encoder의 hidden_size)\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size*2, device=device)\n",
    "#     print(encoder_outputs.shape) ## (647,512)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "        # Encoder의 출력을 encoder_outputs[ei] 에 저장\n",
    "        # encoder_output[0, 0]: (hidden_size,)\n",
    "#         print(encoder_output.shape) ## (1,1,2*512)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    # Decoder의 첫 토큰은 SOS_TOKEN\n",
    "    decoder_input = torch.tensor([[SOS_TOKEN]], device=device)\n",
    "\n",
    "    # Encoder의 마지막 hidden state를 Decoder의 초기 hidden state로 지정\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    # teacher forcing 적용 여부 확률로 결정\n",
    "    # teacher forcing 이란: 정답치를 다음 RNN Cell의 입력으로 넣어주는 경우. 수렴속도가 빠를 수 있으나, 불안정할 수 있음\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    for di in range(target_length):\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "\n",
    "        # loss 계산\n",
    "        loss += criterion(decoder_output.view(1, -1), target_tensor[di])\n",
    "\n",
    "        if use_teacher_forcing:\n",
    "            # teacher forcing 적용: 정답 값 입력\n",
    "            decoder_input = target_tensor[di]\n",
    "        else:\n",
    "            # 확률, 인덱스\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            # 다음 입력으로 주입할 디코더 최종 토큰 결정\n",
    "            decoder_input = topi.squeeze().detach()  # 입력으로 사용할 부분을 히스토리에서 분리\n",
    "\n",
    "        # EOS_TOKEN 이면 종료\n",
    "        if decoder_input.item() == EOS_TOKEN:\n",
    "            break\n",
    "\n",
    "    loss.backward()\n",
    "    \n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef9c1bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_iterations(encoder, decoder, n_iters, dataset, device, print_every=1000, plot_every=100, learning_rate=0.001):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # print_every 마다 초기화\n",
    "    plot_loss_total = 0  # plot_every 마다 초기화\n",
    "\n",
    "    encoder_optimizer = optim.AdamW(encoder.parameters(), lr=learning_rate, betas=(0.9,0.98))\n",
    "    decoder_optimizer = optim.AdamW(decoder.parameters(), lr=learning_rate, betas=(0.9,0.98))\n",
    "    \n",
    "    encoder_scheduler = optim.lr_scheduler.StepLR(optimizer=encoder_optimizer,\n",
    "                                            step_size=10.0,\n",
    "                                            gamma=0.95,\n",
    "                                            verbose=False)\n",
    "    decoder_scheduler = optim.lr_scheduler.StepLR(optimizer=decoder_optimizer,\n",
    "                                                 step_size=10.0,\n",
    "                                                 gamma=0.95,\n",
    "                                                 verbose=False)\n",
    "    \n",
    "    # 랜덤 샘플링된 데이터셋 생성\n",
    "    training_pairs = [dataset[random.randint(0, len(dataset)-1)] for i in range(n_iters)]\n",
    "    \n",
    "    # Loss Function 정의\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # n_iters 만큼 training 시작\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        # 문장 pair\n",
    "        training_pair = training_pairs[iter - 1]        \n",
    "        # 입력 문장\n",
    "        input_tensor = training_pair[0]\n",
    "        # 출력 문장\n",
    "        target_tensor = training_pair[1]\n",
    "        \n",
    "        input_tensor = input_tensor.to(device)\n",
    "        target_tensor = target_tensor.to(device)\n",
    "\n",
    "        # 훈련\n",
    "        loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, \n",
    "                     decoder_optimizer, criterion, device)\n",
    "        encoder_scheduler.step()\n",
    "        decoder_scheduler.step()\n",
    "        \n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        # print_every 마다 loss 출력, 모델 저장\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print(f'{time_since(start, iter/n_iters)} iter: {iter} ({iter/n_iters*100:.1f}%), loss: {print_loss_avg:.4f}')\n",
    "            torch.save({\n",
    "                'encoder_state_dict': encoder.state_dict(),\n",
    "                'decoder_state_dict': decoder.state_dict(),\n",
    "                'encoder_optimizer_state_dict': encoder_optimizer.state_dict(),\n",
    "                'decoder_optimizer_state_dict': decoder_optimizer.state_dict(),\n",
    "                }, \"./model/Text2Text-se2se.pth\")\n",
    "\n",
    "            \n",
    "        # plot_every 마다 loss 시각화\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "        \n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fe153542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-Parameter 정의\n",
    "NUM_VOCABS = 23888\n",
    "HIDDEN_SIZE = 256\n",
    "EMBEDDING_DIM = 256\n",
    "DROPOUT_P = 0.3\n",
    "NUM_LAYERS = 3\n",
    "\n",
    "# Encoder 정의\n",
    "encoder = Encoder(NUM_VOCABS, \n",
    "                  hidden_size=HIDDEN_SIZE, \n",
    "                  embedding_dim=EMBEDDING_DIM, \n",
    "                  num_layers=NUM_LAYERS)\n",
    "\n",
    "# Attention 이 적용된 Decoder 정의\n",
    "decoder = AttentionDecoder(num_vocabs=NUM_VOCABS, \n",
    "                           hidden_size=HIDDEN_SIZE, \n",
    "                           embedding_dim=EMBEDDING_DIM, \n",
    "                           dropout_p=DROPOUT_P, \n",
    "                           max_length=MAX_LENGTH)\n",
    "\n",
    "# encoder, decoder 생성 및 device 지정\n",
    "encoder = encoder.to(device)\n",
    "decoder = decoder.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0440bfe2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttentionDecoder(\n",
       "  (embedding): Embedding(23888, 256)\n",
       "  (attn): Linear(in_features=512, out_features=358, bias=True)\n",
       "  (attn_combine): Linear(in_features=768, out_features=256, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (gru): GRU(256, 256, batch_first=True, dropout=0.3)\n",
       "  (out): Linear(in_features=256, out_features=23888, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85cb500a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (pos_encoder): PositionalEncoding()\n",
       "  (embedding): Embedding(23888, 256)\n",
       "  (encoder_layer): TransformerEncoderLayer(\n",
       "    (self_attn): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "    )\n",
       "    (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "    (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout1): Dropout(p=0.1, inplace=False)\n",
       "    (dropout2): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (transformer_encoder): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=256, out_features=256, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (gru): GRU(256, 256, num_layers=3, batch_first=True, dropout=0.2, bidirectional=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3013b557",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder: x torch.Size([1])\n",
      "encoder torch.Size([1, 256])\n",
      "encoder: x torch.Size([1])\n",
      "encoder torch.Size([1, 256])\n",
      "encoder: x torch.Size([1])\n",
      "encoder torch.Size([1, 256])\n",
      "encoder: x torch.Size([1])\n",
      "encoder torch.Size([1, 256])\n",
      "encoder: x torch.Size([1])\n",
      "encoder torch.Size([1, 256])\n",
      "encoder: x torch.Size([1])\n",
      "encoder torch.Size([1, 256])\n",
      "encoder: x torch.Size([1])\n",
      "encoder torch.Size([1, 256])\n",
      "decoder: x torch.Size([1])\n",
      "decoder torch.Size([1, 1, 256])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[116], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_iterations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[114], line 40\u001b[0m, in \u001b[0;36mtrain_iterations\u001b[0;34m(encoder, decoder, n_iters, dataset, device, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[1;32m     37\u001b[0m target_tensor \u001b[38;5;241m=\u001b[39m target_tensor\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# 훈련\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m             \u001b[49m\u001b[43mdecoder_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m encoder_scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     43\u001b[0m decoder_scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[0;32mIn[113], line 40\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, device, max_length, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m     37\u001b[0m use_teacher_forcing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m random\u001b[38;5;241m.\u001b[39mrandom() \u001b[38;5;241m<\u001b[39m teacher_forcing_ratio \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m di \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(target_length):\n\u001b[0;32m---> 40\u001b[0m     decoder_output, decoder_hidden, decoder_attention \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoder_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder_hidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# loss 계산\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m criterion(decoder_output\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), target_tensor[di])\n",
      "File \u001b[0;32m~/.conda/envs/virtual/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[109], line 33\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[0;34m(self, x, hidden, encoder_outputs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoder\u001b[39m\u001b[38;5;124m\"\u001b[39m, embedded\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     32\u001b[0m x \u001b[38;5;241m=\u001b[39m embedded\n\u001b[0;32m---> 33\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpos_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Using last layer of GRU for attention mechanism\u001b[39;00m\n\u001b[1;32m     37\u001b[0m hidden_last_layer \u001b[38;5;241m=\u001b[39m hidden[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/virtual/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[11], line 41\u001b[0m, in \u001b[0;36mPositionalEncoding.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;66;03m# self.encoding\u001b[39;00m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# [max_len = 512, d_model = 512]\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m# batch_size = 128, seq_len = 30\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m     batch_size, seq_len \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize() \n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m# [seq_len = 30, d_model = 512]\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# [128, 30, 512]의 size를 가지는 token embedding에 더해질 것이다. \u001b[39;00m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m# \u001b[39;00m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding[:seq_len, :]\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "train_iterations(encoder, decoder, 100, dataset, device, print_every=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ef3f20",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "42029d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, input_tensor, dataset, device, max_length=MAX_LENGTH):\n",
    "    # Eval 모드 설정\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        input_length = input_tensor.size(0)\n",
    "\n",
    "        # Encoder의 hidden state 초기화\n",
    "        encoder_hidden = encoder.init_hidden(device=device)\n",
    "  \n",
    "\n",
    "        # encoder_outputs는 Encoder를 통과한 문장의 출력\n",
    "        # (max_length, hidden_size)\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size*2, device=device)\n",
    " \n",
    "        \n",
    "        # Encoder 에 입력 문자 주입 후 encoder_outputs 생성\n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "\n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "\n",
    "        # Decoder의 첫 번째 입력으로 SOS_TOKEN 입력(SOS_TOKEN=0)\n",
    "        decoder_input = torch.tensor([[0]], device=device)\n",
    "  \n",
    "        # Decoder의 첫 번째 hidden state는 Encoder의 마지막 hidden state 사용\n",
    "        decoder_hidden = encoder_hidden\n",
    "    \n",
    "\n",
    "        decoded_words = []\n",
    "      \n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "      \n",
    "        for di in range(max_length):\n",
    "            # 1개의 Decoder 입력 토큰을 통과\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            # Attention 시각화를 위한 tensor 저장\n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            # 출력 토큰 예측\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            \n",
    "            # EOS_TOKEN이면 종료\n",
    "            if topi.item() == dataset.EOS_TOKEN:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                # 출력 문장에 토큰 시퀀스(index)를 단어(word)로 변환한 후 저장\n",
    "                decoded_words.append(dataset.wordvocab.index_to_word(topi.item()))\n",
    "\n",
    "            # decoder_input은 다음 토큰 예측시 입력 값\n",
    "            # decoder_input: (hidden_size,)\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        return decoded_words, decoder_attentions[:di + 1]\n",
    "    \n",
    "    \n",
    "def evaluate_randomly(encoder, decoder, dataset, device, n=10):\n",
    "    for i in range(n):\n",
    "        # 랜덤 샘플링\n",
    "        x, y = random.choice(dataset)\n",
    "        # 입력 문장, 출력 문장 (Ground Truth)\n",
    "        print('>', dataset.sequences_to_texts(x))\n",
    "        print('=', dataset.sequences_to_texts(y))\n",
    "\n",
    "        # 예측\n",
    "        output_words, attentions = evaluate(encoder, decoder, x.to(device), dataset, device)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        \n",
    "        # 예측 문장 출력\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14be857",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QADataset():\n",
    "    def __init__(self, input_seq, min_length=1, max_length=647):\n",
    "        data_dir = 'data'\n",
    "        \n",
    "        # TOKEN 정의\n",
    "        self.SOS_TOKEN = 0 # SOS 토큰\n",
    "        self.EOS_TOKEN = 1 # EOS 토큰\n",
    "        \n",
    "        self.tagger = Okt()   # 형태소 분석기\n",
    "        self.max_length = max_length # 한 문장의 최대 길이 지정\n",
    "        \n",
    "        # CSV 데이터 로드\n",
    "        df = pd.read_csv(csv_path)\n",
    "        \n",
    "        # 한글 정규화\n",
    "        korean_pattern = r'[^ ?,.!A-Za-z0-9가-힣+]'\n",
    "        self.normalizer = re.compile(korean_pattern)\n",
    "        \n",
    "        # src: 질의, tgt: 답변\n",
    "        src_clean = []\n",
    "        tgt_clean = []\n",
    "        \n",
    "        # 단어 사전 생성\n",
    "        wordvocab = WordVocab()\n",
    "        \n",
    "        for _, row in df.iterrows():\n",
    "            src = row['value']\n",
    "            tgt = row['label']\n",
    "            \n",
    "            # 한글 전처리\n",
    "            src = self.clean_text(src)\n",
    "            tgt = self.clean_text(tgt)\n",
    "            \n",
    "            if len(src.split()) > min_length and len(tgt.split()) > min_length:\n",
    "                # 최소 길이를 넘어가는 문장의 단어만 추가\n",
    "                wordvocab.add_sentence(src)\n",
    "                wordvocab.add_sentence(tgt)\n",
    "                src_clean.append(src)\n",
    "                tgt_clean.append(tgt)            \n",
    "        \n",
    "        self.srcs = src_clean\n",
    "        self.tgts = tgt_clean\n",
    "        self.wordvocab = wordvocab\n",
    "        \n",
    "\n",
    "    \n",
    "    def normalize(self, sentence):\n",
    "        # 정규표현식에 따른 한글 정규화\n",
    "        return self.normalizer.sub(\"\", sentence)\n",
    "\n",
    "    def clean_text(self, sentence):\n",
    "        # 한글 정규화\n",
    "        sentence = self.normalize(str(sentence))\n",
    "        # 형태소 처리\n",
    "        sentence = self.tagger.morphs(sentence)\n",
    "        sentence = ' '.join(sentence)\n",
    "        sentence = sentence.lower()\n",
    "        return sentence\n",
    "    \n",
    "    def texts_to_sequences(self, sentence):\n",
    "        # 문장 -> 시퀀스로 변환\n",
    "        sequences = [self.wordvocab.word_to_index(w) for w in sentence.split()]\n",
    "        # 문장 최대 길이 -1 까지 슬라이싱\n",
    "        sequences = sequences[:self.max_length-1]\n",
    "        # 맨 마지막에 EOS TOKEN 추가\n",
    "        sequences.append(self.EOS_TOKEN)\n",
    "        return sequences\n",
    "    \n",
    "    def sequences_to_texts(self, sequences):\n",
    "        # 시퀀스 -> 문장으로 변환\n",
    "        sentences = [self.wordvocab.index_to_word(s.item()) for s in sequences]\n",
    "        return ' '.join(sentences)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        inputs = self.srcs[idx]\n",
    "        inputs_sequences = self.texts_to_sequences(inputs)\n",
    "        \n",
    "        outputs = self.tgts[idx]\n",
    "        outputs_sequences = self.texts_to_sequences(outputs)\n",
    "        \n",
    "        return torch.tensor(inputs_sequences).view(-1, 1), torch.tensor(outputs_sequences).view(-1, 1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.srcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f581211c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 혹시 좋아하는 주말 드라마 가 있을까요 <EOS>\n",
      "= 그 일욜 토요일 하고 일요일 날 여덟 시 에 하는 거 제목 은 잘 생각 이 안 나는데 요즘 그거 하나 밖에는 보는 건 없고요 <EOS>\n",
      "< 저 는 <EOS>\n",
      "\n",
      "> name 1 씨 는 폐지 줍는 할머니 할아버지 분 들 을 보신 적 이 있으신 가요 <EOS>\n",
      "= 어 저 는 되게 많은 거 같아요 <EOS>\n",
      "< 저 는 <EOS>\n",
      "\n",
      "> 에 혹시 다른 뭐 동남아 제 가 관심 있어 한 태국 베트남 뭐 이런 쪽 인데 혹시 가보신 적 있으세요 <EOS>\n",
      "= 아 에 저 는 캄보디아 에서 한 6 개월 정도 살았던 경험 이 있어서 캄보디아 쪽 잘 알 고 있고요 <EOS>\n",
      "< 저 는 <EOS>\n",
      "\n",
      "> 어 그런 델 가야 되는데 어우 야 저 뭐 야 저기 한번 가 봤더니 그 저수지 처럼 딱 막아놨는데에 밑 에 펄 이 막 그 썩어가지고 왜 썩는 줄 알 아 <EOS>\n",
      "= 사료 있지 ? <EOS>\n",
      "< 저 는 <EOS>\n",
      "\n",
      "> 그렇다면은 가장 최근 에 본 영화 가 아까 한국 영화 를 얘기 해 주셨는데 다른 외국 영화 는 없으신 가요 <EOS>\n",
      "= 그리고 그 내용 이 있다면 어떤 내용 이 있을까요 ? <EOS>\n",
      "< 저 는 <EOS>\n",
      "\n",
      "> 학창 시절 에 갖고 계신 꿈 이나 아니면 지금 갖고 계시는 꿈 이 있을까요 <EOS>\n",
      "= 어렸을 때 그림 그리는 걸 좋아했었거든요 ? <EOS>\n",
      "< 저 는 <EOS>\n",
      "\n",
      "> 맨시티 직 간 하고 싶은데 아직 까진 못 해 봐가지고 계속 지금 나 의 드림 인데 가보셨 다고 하니 그 내용 을 조금 어 듣고 싶은데 어땠는지 누구 팀 을 좋아하시는지 한번 여쭤 봐도 될까 요 <EOS>\n",
      "= 네 저 는 사실 저 는 축구 를 좋아한 지 그렇게 오래 는 안 됐어요 <EOS>\n",
      "< 저 는 <EOS>\n",
      "\n",
      "> 남자 들 만 그 래야 돼 <EOS>\n",
      "= 거기 에 대해 서 불만 이 많지 <EOS>\n",
      "< 저 는 <EOS>\n",
      "\n",
      "> 호프 집 이 시간대 도 근데 밤 이긴 해서 조금 힘들긴 한데 제 가 쿠팡 에서 일 할 때 는 아예 낮 과 밤 이 바뀐 상태 라서 괜찮은데 호프 집은 학교 다닐 때 일 을 했었거든요 <EOS>\n",
      "= 새벽 한 세 시 까지 하는 날 은 힘들긴 했는데 솔직히 급여 도 그냥 최저 에 야간 수당 만 주는 그런 거 였지만 가끔 씩 손님 들 이 고생 한다고 5만 원 씩 아니면 10000원 씩 팁 을 줄 때 가 있어요 <EOS>\n",
      "< 저 는 <EOS>\n",
      "\n",
      "> 그 영세 스포츠 스타 들 말 제 외한 다 면 은 그러니까 가능하지 일반 직장인 이었으면 못 할 그런 거 아닐까 란 생각 이 들 기도 하고 근데 코로나 때문 에 이 게 경기 수가 아예 안 하는 거야 아니면 한시 적 으로 쪼끔씩 쪼금씩 경기 를 하는 거야 <EOS>\n",
      "= 유럽 리그 는 그러니까 내 가 알 고 있기 로는 계속 경기 는 하고 있는데 무관 중 으로만 경기 가 진행 이 되는 거야 <EOS>\n",
      "< 저 는 <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 랜덤 샘플링 된 데이터 evaluate\n",
    "evaluate_randomly(encoder, decoder, dataset, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dc8fd0",
   "metadata": {},
   "source": [
    "attention 가중치 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c0fb8a34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1600x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Attention Weights를 활용한 시각화\n",
    "output_words, attentions = evaluate(encoder, decoder, dataset[2][0].to(device), dataset, device)\n",
    "plt.matshow(attentions.numpy())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e175459d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention 시각화를 위한 함수\n",
    "def show_attention(input_sentence, output_words, attentions):\n",
    "    # colorbar로 그림 설정\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # 축 설정\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') + ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # 매 틱마다 라벨 보여주기\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluate_and_show_attention(encoder, decoder, input_sentence, dataset, device):\n",
    "    output_words, attentions = evaluate(encoder, decoder, input_sentence.to(device), dataset, device)\n",
    "    input_sentence = dataset.sequences_to_texts(input_sentence)\n",
    "    output_words = ' '.join(output_words)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', output_words)\n",
    "    show_attention(input_sentence, output_words.split(), attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "de506044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[23],\n",
       "        [24],\n",
       "        [64],\n",
       "        [65],\n",
       "        [54],\n",
       "        [66],\n",
       "        [50],\n",
       "        [42],\n",
       "        [67],\n",
       "        [68],\n",
       "        [40],\n",
       "        [41],\n",
       "        [22],\n",
       "        [69],\n",
       "        [20],\n",
       "        [70],\n",
       "        [71],\n",
       "        [ 1]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "951258db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = 제 가 생각 하는 반려동물 키우기 위 한 필요한 세 가지는 일단 반려동물 을 사랑 하는 마음 그리고 반려동물 을 키우기 위해 적정한 적절한 공간 을 제공 해야 될 경제 적 그리고 반려동물 과 함께 해줄 해줘야 하는 시간 이 필요하다고 생각 을 하고 있습니다 <EOS>\n",
      "output = 저 는 <EOS>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n",
      "findfont: Font family 'NanumGothic' not found.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_and_show_attention(encoder, decoder, dataset[2][1], dataset, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3d90aabc",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "In FT2Font: Can not load face (unknown file format; error code 0x2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfont_manager\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mfm\u001b[39;00m\n\u001b[1;32m      3\u001b[0m fonts \u001b[38;5;241m=\u001b[39m fm\u001b[38;5;241m.\u001b[39mfindSystemFonts()\n\u001b[0;32m----> 4\u001b[0m font_names \u001b[38;5;241m=\u001b[39m [fm\u001b[38;5;241m.\u001b[39mFontProperties(fname\u001b[38;5;241m=\u001b[39mfont)\u001b[38;5;241m.\u001b[39mget_name() \u001b[38;5;28;01mfor\u001b[39;00m font \u001b[38;5;129;01min\u001b[39;00m fonts]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(font_names)\n",
      "Cell \u001b[0;32mIn[54], line 4\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfont_manager\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mfm\u001b[39;00m\n\u001b[1;32m      3\u001b[0m fonts \u001b[38;5;241m=\u001b[39m fm\u001b[38;5;241m.\u001b[39mfindSystemFonts()\n\u001b[0;32m----> 4\u001b[0m font_names \u001b[38;5;241m=\u001b[39m [\u001b[43mfm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFontProperties\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfont\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m font \u001b[38;5;129;01min\u001b[39;00m fonts]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(font_names)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/font_manager.py:662\u001b[0m, in \u001b[0;36mFontProperties.get_name\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_name\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    659\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    660\u001b[0m \u001b[38;5;124;03m    Return the name of the font that best matches the font properties.\u001b[39;00m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 662\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_font\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfindfont\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfamily_name\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/_api/deprecation.py:297\u001b[0m, in \u001b[0;36mrename_parameter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    292\u001b[0m     warn_deprecated(\n\u001b[1;32m    293\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mold\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m() \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas been renamed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m since Matplotlib \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msince\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; support \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    295\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor the old name will be dropped %(removal)s.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    296\u001b[0m     kwargs[new] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(old)\n\u001b[0;32m--> 297\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/font_manager.py:1520\u001b[0m, in \u001b[0;36mget_font\u001b[0;34m(font_filepaths, hinting_factor)\u001b[0m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hinting_factor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1518\u001b[0m     hinting_factor \u001b[38;5;241m=\u001b[39m mpl\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext.hinting_factor\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m-> 1520\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_font\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1521\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# must be a tuple to be cached\u001b[39;49;00m\n\u001b[1;32m   1522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1523\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhinting_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1524\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_kerning_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrcParams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext.kerning_factor\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1525\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# also key on the thread ID to prevent segfaults with multi-threading\u001b[39;49;00m\n\u001b[1;32m   1526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthread_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreading\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_ident\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/matplotlib/font_manager.py:1461\u001b[0m, in \u001b[0;36m_get_font\u001b[0;34m(font_filepaths, hinting_factor, _kerning_factor, thread_id)\u001b[0m\n\u001b[1;32m   1458\u001b[0m \u001b[38;5;129m@lru_cache\u001b[39m(\u001b[38;5;241m64\u001b[39m)\n\u001b[1;32m   1459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_font\u001b[39m(font_filepaths, hinting_factor, \u001b[38;5;241m*\u001b[39m, _kerning_factor, thread_id):\n\u001b[1;32m   1460\u001b[0m     first_fontpath, \u001b[38;5;241m*\u001b[39mrest \u001b[38;5;241m=\u001b[39m font_filepaths\n\u001b[0;32m-> 1461\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mft2font\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFT2Font\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfirst_fontpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhinting_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fallback_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[43m            \u001b[49m\u001b[43mft2font\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFT2Font\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1465\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhinting_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1466\u001b[0m \u001b[43m                \u001b[49m\u001b[43m_kerning_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_kerning_factor\u001b[49m\n\u001b[1;32m   1467\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1468\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrest\u001b[49m\n\u001b[1;32m   1469\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1470\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_kerning_factor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_kerning_factor\u001b[49m\n\u001b[1;32m   1471\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: In FT2Font: Can not load face (unknown file format; error code 0x2)"
     ]
    }
   ],
   "source": [
    "import matplotlib.font_manager as fm\n",
    "\n",
    "fonts = fm.findSystemFonts()\n",
    "font_names = [fm.FontProperties(fname=font).get_name() for font in fonts]\n",
    "\n",
    "print(font_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a425bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
