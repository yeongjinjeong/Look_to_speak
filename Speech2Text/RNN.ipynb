{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset\n",
    "import torchaudio\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from konlpy.tag import Okt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"text/part1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>form</th>\n",
       "      <th>original_form</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SDRW2000000319.1.1.1</td>\n",
       "      <td>병역 특례를 받아</td>\n",
       "      <td>병역 특례를 받아</td>\n",
       "      <td>SD2001645</td>\n",
       "      <td>4.04903</td>\n",
       "      <td>5.83905</td>\n",
       "      <td>10대</td>\n",
       "      <td>여성</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SDRW2000000319.1.1.2</td>\n",
       "      <td>법정 봉사활동 기 시간을 채워야 하는</td>\n",
       "      <td>법정 봉사활동 기 시간을 채워야 하는</td>\n",
       "      <td>SD2001645</td>\n",
       "      <td>5.84901</td>\n",
       "      <td>8.89405</td>\n",
       "      <td>10대</td>\n",
       "      <td>여성</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SDRW2000000319.1.1.3</td>\n",
       "      <td>예술</td>\n",
       "      <td>예술</td>\n",
       "      <td>SD2001645</td>\n",
       "      <td>8.90407</td>\n",
       "      <td>9.52506</td>\n",
       "      <td>10대</td>\n",
       "      <td>여성</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SDRW2000000319.1.1.4</td>\n",
       "      <td>또는 체육 요원의 절반가량이</td>\n",
       "      <td>또는 체육 요원의 절반가량이</td>\n",
       "      <td>SD2001645</td>\n",
       "      <td>9.53506</td>\n",
       "      <td>12.05203</td>\n",
       "      <td>10대</td>\n",
       "      <td>여성</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SDRW2000000319.1.1.5</td>\n",
       "      <td>허위 자료를 내거나</td>\n",
       "      <td>허위 자료를 내거나</td>\n",
       "      <td>SD2001645</td>\n",
       "      <td>12.06204</td>\n",
       "      <td>13.79504</td>\n",
       "      <td>10대</td>\n",
       "      <td>여성</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213188</th>\n",
       "      <td>SDRW2000000418.1.1.326</td>\n",
       "      <td>우선</td>\n",
       "      <td>우선</td>\n",
       "      <td>SD2000552</td>\n",
       "      <td>908.12707</td>\n",
       "      <td>909.98106</td>\n",
       "      <td>10대</td>\n",
       "      <td>여성</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213189</th>\n",
       "      <td>SDRW2000000418.1.1.327</td>\n",
       "      <td>맛있는 음식들 먹으면서</td>\n",
       "      <td>맛있는 음식들 먹으면서</td>\n",
       "      <td>SD2000552</td>\n",
       "      <td>909.99104</td>\n",
       "      <td>912.25405</td>\n",
       "      <td>10대</td>\n",
       "      <td>여성</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213190</th>\n",
       "      <td>SDRW2000000418.1.1.328</td>\n",
       "      <td>겝</td>\n",
       "      <td>겝</td>\n",
       "      <td>SD2000552</td>\n",
       "      <td>912.26403</td>\n",
       "      <td>913.64807</td>\n",
       "      <td>10대</td>\n",
       "      <td>여성</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213191</th>\n",
       "      <td>SDRW2000000418.1.1.329</td>\n",
       "      <td>먹으면서 저도 같이 맛있어 보이는 느낌이라서</td>\n",
       "      <td>먹으면서 저도 같이 맛있어 보이는 느낌이라서</td>\n",
       "      <td>SD2000552</td>\n",
       "      <td>913.65802</td>\n",
       "      <td>917.87305</td>\n",
       "      <td>10대</td>\n",
       "      <td>여성</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213192</th>\n",
       "      <td>SDRW2000000418.1.1.330</td>\n",
       "      <td>더 좋은 거 같아요.</td>\n",
       "      <td>더 좋은 거 같아요.</td>\n",
       "      <td>SD2000552</td>\n",
       "      <td>917.88301</td>\n",
       "      <td>919.84207</td>\n",
       "      <td>10대</td>\n",
       "      <td>여성</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>213193 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            id                      form   \n",
       "0         SDRW2000000319.1.1.1                 병역 특례를 받아  \\\n",
       "1         SDRW2000000319.1.1.2      법정 봉사활동 기 시간을 채워야 하는   \n",
       "2         SDRW2000000319.1.1.3                        예술   \n",
       "3         SDRW2000000319.1.1.4           또는 체육 요원의 절반가량이   \n",
       "4         SDRW2000000319.1.1.5                허위 자료를 내거나   \n",
       "...                        ...                       ...   \n",
       "213188  SDRW2000000418.1.1.326                        우선   \n",
       "213189  SDRW2000000418.1.1.327              맛있는 음식들 먹으면서   \n",
       "213190  SDRW2000000418.1.1.328                         겝   \n",
       "213191  SDRW2000000418.1.1.329  먹으면서 저도 같이 맛있어 보이는 느낌이라서   \n",
       "213192  SDRW2000000418.1.1.330               더 좋은 거 같아요.   \n",
       "\n",
       "                   original_form speaker_id      start        end  age sex  \n",
       "0                      병역 특례를 받아  SD2001645    4.04903    5.83905  10대  여성  \n",
       "1           법정 봉사활동 기 시간을 채워야 하는  SD2001645    5.84901    8.89405  10대  여성  \n",
       "2                             예술  SD2001645    8.90407    9.52506  10대  여성  \n",
       "3                또는 체육 요원의 절반가량이  SD2001645    9.53506   12.05203  10대  여성  \n",
       "4                     허위 자료를 내거나  SD2001645   12.06204   13.79504  10대  여성  \n",
       "...                          ...        ...        ...        ...  ...  ..  \n",
       "213188                        우선  SD2000552  908.12707  909.98106  10대  여성  \n",
       "213189              맛있는 음식들 먹으면서  SD2000552  909.99104  912.25405  10대  여성  \n",
       "213190                         겝  SD2000552  912.26403  913.64807  10대  여성  \n",
       "213191  먹으면서 저도 같이 맛있어 보이는 느낌이라서  SD2000552  913.65802  917.87305  10대  여성  \n",
       "213192               더 좋은 거 같아요.  SD2000552  917.88301  919.84207  10대  여성  \n",
       "\n",
       "[213193 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output, hidden = self.rnn(x)\n",
    "        output = self.fc(output[:, -1, :])\n",
    "        return self.relu(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                0\n",
       "form             39\n",
       "original_form     0\n",
       "speaker_id        0\n",
       "start             0\n",
       "end               0\n",
       "age               0\n",
       "sex               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex\n",
       "여성    149045\n",
       "남성     64109\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['sex'] == '여성']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex\n",
       "여성    149045\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "okt = Okt()\n",
    "df['token']=df['form'].apply(okt.morphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>id</th>\n",
       "      <th>form</th>\n",
       "      <th>original_form</th>\n",
       "      <th>speaker_id</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>SDRW2000000319.1.1.1</td>\n",
       "      <td>병역 특례를 받아</td>\n",
       "      <td>병역 특례를 받아</td>\n",
       "      <td>SD2001645</td>\n",
       "      <td>4.04903</td>\n",
       "      <td>5.83905</td>\n",
       "      <td>10대</td>\n",
       "      <td>여성</td>\n",
       "      <td>[병역, 특례, 를, 받아]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>SDRW2000000319.1.1.2</td>\n",
       "      <td>법정 봉사활동 기 시간을 채워야 하는</td>\n",
       "      <td>법정 봉사활동 기 시간을 채워야 하는</td>\n",
       "      <td>SD2001645</td>\n",
       "      <td>5.84901</td>\n",
       "      <td>8.89405</td>\n",
       "      <td>10대</td>\n",
       "      <td>여성</td>\n",
       "      <td>[법정, 봉사활동, 기, 시간, 을, 채워야, 하는]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>SDRW2000000319.1.1.3</td>\n",
       "      <td>예술</td>\n",
       "      <td>예술</td>\n",
       "      <td>SD2001645</td>\n",
       "      <td>8.90407</td>\n",
       "      <td>9.52506</td>\n",
       "      <td>10대</td>\n",
       "      <td>여성</td>\n",
       "      <td>[예술]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>SDRW2000000319.1.1.4</td>\n",
       "      <td>또는 체육 요원의 절반가량이</td>\n",
       "      <td>또는 체육 요원의 절반가량이</td>\n",
       "      <td>SD2001645</td>\n",
       "      <td>9.53506</td>\n",
       "      <td>12.05203</td>\n",
       "      <td>10대</td>\n",
       "      <td>여성</td>\n",
       "      <td>[또는, 체육, 요원, 의, 절반, 가량, 이]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>SDRW2000000319.1.1.5</td>\n",
       "      <td>허위 자료를 내거나</td>\n",
       "      <td>허위 자료를 내거나</td>\n",
       "      <td>SD2001645</td>\n",
       "      <td>12.06204</td>\n",
       "      <td>13.79504</td>\n",
       "      <td>10대</td>\n",
       "      <td>여성</td>\n",
       "      <td>[허위, 자료, 를, 내, 거나]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149040</th>\n",
       "      <td>213188</td>\n",
       "      <td>SDRW2000000418.1.1.326</td>\n",
       "      <td>우선</td>\n",
       "      <td>우선</td>\n",
       "      <td>SD2000552</td>\n",
       "      <td>908.12707</td>\n",
       "      <td>909.98106</td>\n",
       "      <td>10대</td>\n",
       "      <td>여성</td>\n",
       "      <td>[우선]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149041</th>\n",
       "      <td>213189</td>\n",
       "      <td>SDRW2000000418.1.1.327</td>\n",
       "      <td>맛있는 음식들 먹으면서</td>\n",
       "      <td>맛있는 음식들 먹으면서</td>\n",
       "      <td>SD2000552</td>\n",
       "      <td>909.99104</td>\n",
       "      <td>912.25405</td>\n",
       "      <td>10대</td>\n",
       "      <td>여성</td>\n",
       "      <td>[맛있는, 음식, 들, 먹으면서]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149042</th>\n",
       "      <td>213190</td>\n",
       "      <td>SDRW2000000418.1.1.328</td>\n",
       "      <td>겝</td>\n",
       "      <td>겝</td>\n",
       "      <td>SD2000552</td>\n",
       "      <td>912.26403</td>\n",
       "      <td>913.64807</td>\n",
       "      <td>10대</td>\n",
       "      <td>여성</td>\n",
       "      <td>[겝]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149043</th>\n",
       "      <td>213191</td>\n",
       "      <td>SDRW2000000418.1.1.329</td>\n",
       "      <td>먹으면서 저도 같이 맛있어 보이는 느낌이라서</td>\n",
       "      <td>먹으면서 저도 같이 맛있어 보이는 느낌이라서</td>\n",
       "      <td>SD2000552</td>\n",
       "      <td>913.65802</td>\n",
       "      <td>917.87305</td>\n",
       "      <td>10대</td>\n",
       "      <td>여성</td>\n",
       "      <td>[먹으면서, 저, 도, 같이, 맛있어, 보이는, 느낌, 이라서]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149044</th>\n",
       "      <td>213192</td>\n",
       "      <td>SDRW2000000418.1.1.330</td>\n",
       "      <td>더 좋은 거 같아요.</td>\n",
       "      <td>더 좋은 거 같아요.</td>\n",
       "      <td>SD2000552</td>\n",
       "      <td>917.88301</td>\n",
       "      <td>919.84207</td>\n",
       "      <td>10대</td>\n",
       "      <td>여성</td>\n",
       "      <td>[더, 좋은, 거, 같아요, .]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149045 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index                      id                      form   \n",
       "0            0    SDRW2000000319.1.1.1                 병역 특례를 받아  \\\n",
       "1            1    SDRW2000000319.1.1.2      법정 봉사활동 기 시간을 채워야 하는   \n",
       "2            2    SDRW2000000319.1.1.3                        예술   \n",
       "3            3    SDRW2000000319.1.1.4           또는 체육 요원의 절반가량이   \n",
       "4            4    SDRW2000000319.1.1.5                허위 자료를 내거나   \n",
       "...        ...                     ...                       ...   \n",
       "149040  213188  SDRW2000000418.1.1.326                        우선   \n",
       "149041  213189  SDRW2000000418.1.1.327              맛있는 음식들 먹으면서   \n",
       "149042  213190  SDRW2000000418.1.1.328                         겝   \n",
       "149043  213191  SDRW2000000418.1.1.329  먹으면서 저도 같이 맛있어 보이는 느낌이라서   \n",
       "149044  213192  SDRW2000000418.1.1.330               더 좋은 거 같아요.   \n",
       "\n",
       "                   original_form speaker_id      start        end  age sex   \n",
       "0                      병역 특례를 받아  SD2001645    4.04903    5.83905  10대  여성  \\\n",
       "1           법정 봉사활동 기 시간을 채워야 하는  SD2001645    5.84901    8.89405  10대  여성   \n",
       "2                             예술  SD2001645    8.90407    9.52506  10대  여성   \n",
       "3                또는 체육 요원의 절반가량이  SD2001645    9.53506   12.05203  10대  여성   \n",
       "4                     허위 자료를 내거나  SD2001645   12.06204   13.79504  10대  여성   \n",
       "...                          ...        ...        ...        ...  ...  ..   \n",
       "149040                        우선  SD2000552  908.12707  909.98106  10대  여성   \n",
       "149041              맛있는 음식들 먹으면서  SD2000552  909.99104  912.25405  10대  여성   \n",
       "149042                         겝  SD2000552  912.26403  913.64807  10대  여성   \n",
       "149043  먹으면서 저도 같이 맛있어 보이는 느낌이라서  SD2000552  913.65802  917.87305  10대  여성   \n",
       "149044               더 좋은 거 같아요.  SD2000552  917.88301  919.84207  10대  여성   \n",
       "\n",
       "                                      token  \n",
       "0                           [병역, 특례, 를, 받아]  \n",
       "1             [법정, 봉사활동, 기, 시간, 을, 채워야, 하는]  \n",
       "2                                      [예술]  \n",
       "3                [또는, 체육, 요원, 의, 절반, 가량, 이]  \n",
       "4                        [허위, 자료, 를, 내, 거나]  \n",
       "...                                     ...  \n",
       "149040                                 [우선]  \n",
       "149041                   [맛있는, 음식, 들, 먹으면서]  \n",
       "149042                                  [겝]  \n",
       "149043  [먹으면서, 저, 도, 같이, 맛있어, 보이는, 느낌, 이라서]  \n",
       "149044                   [더, 좋은, 거, 같아요, .]  \n",
       "\n",
       "[149045 rows x 10 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_list = []\n",
    "for i in range(len(df.index)):\n",
    "    bin_list.append(df[\"token\"][i])\n",
    "bin_list = sum(bin_list,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_list2 = []\n",
    "for i in range(len(bin_list)):\n",
    "    temp = bin_list[i]\n",
    "    if temp not in bin_list2:\n",
    "        bin_list2.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup = {tkn: i+2 for i, tkn in enumerate(bin_list2)}\n",
    "lookup[\"unk\"] = 0\n",
    "lookup[\"pad\"] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, wav_dir, bin_list):\n",
    "        self.data = dataframe\n",
    "        self.wav_dir = wav_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file_id = self.data.iloc[index]['id']\n",
    "        wav_path = os.path.join(self.wav_dir, f'{file_id}.wav')\n",
    "        audio, _ = torchaudio.load(wav_path)\n",
    "        text = self.data.iloc[index]['token']\n",
    "        \n",
    "        token_indices = [lookup[t] for t in text]\n",
    "        desired_length = 100\n",
    "        \n",
    "        token_indices += [1] * (desired_length - len(token_indices))\n",
    "        token_indices = torch.tensor(token_indices).type(torch.float32)\n",
    "\n",
    "        return audio, token_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "batch_size = 100\n",
    "learning_rate = 2e-03\n",
    "num_classes = len(df)  \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_dir = './wav_all_stereo(fixed_length)'\n",
    "dataset = CustomDataset(df, wav_dir, bin_list2)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio: tensor([[-9.1553e-05,  3.0518e-05,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [-9.1553e-05,  3.0518e-05,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00]])\n",
      "Text: tensor([2., 3., 4., 5., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "audio, text = dataset[0]\n",
    "print(\"Audio:\", audio)\n",
    "print(\"Text:\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 221616\n",
    "hidden_size = 100\n",
    "output_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNNModel(input_size, hidden_size, output_size).to(device)\n",
    "criterion = nn.HuberLoss()\n",
    "optimizer = optim.NAdam(model.parameters(), lr=learning_rate)\n",
    "total_step = len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"./model/speech2text.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step [10/1491], Loss: 113.6651\n",
      "Epoch [1/100], Step [20/1491], Loss: 132.6153\n",
      "Epoch [1/100], Step [30/1491], Loss: 126.5062\n",
      "Epoch [1/100], Step [40/1491], Loss: 157.0523\n",
      "Epoch [1/100], Step [50/1491], Loss: 108.9767\n",
      "Epoch [1/100], Step [60/1491], Loss: 146.2619\n",
      "Epoch [1/100], Step [70/1491], Loss: 151.1003\n",
      "Epoch [1/100], Step [80/1491], Loss: 152.7087\n",
      "Epoch [1/100], Step [90/1491], Loss: 104.4436\n",
      "Epoch [1/100], Step [100/1491], Loss: 154.5409\n",
      "Epoch [1/100], Step [110/1491], Loss: 124.9002\n",
      "Epoch [1/100], Step [120/1491], Loss: 129.5215\n",
      "Epoch [1/100], Step [130/1491], Loss: 133.3344\n",
      "Epoch [1/100], Step [140/1491], Loss: 122.3453\n",
      "Epoch [1/100], Step [150/1491], Loss: 125.1144\n",
      "Epoch [1/100], Step [160/1491], Loss: 89.4354\n",
      "Epoch [1/100], Step [170/1491], Loss: 134.0513\n",
      "Epoch [1/100], Step [180/1491], Loss: 99.1525\n",
      "Epoch [1/100], Step [190/1491], Loss: 119.6255\n",
      "Epoch [1/100], Step [200/1491], Loss: 118.1781\n",
      "Epoch [1/100], Step [210/1491], Loss: 133.0045\n",
      "Epoch [1/100], Step [220/1491], Loss: 114.2552\n",
      "Epoch [1/100], Step [230/1491], Loss: 114.7936\n",
      "Epoch [1/100], Step [240/1491], Loss: 114.4529\n",
      "Epoch [1/100], Step [250/1491], Loss: 119.7615\n",
      "Epoch [1/100], Step [260/1491], Loss: 128.1975\n",
      "Epoch [1/100], Step [270/1491], Loss: 133.8702\n",
      "Epoch [1/100], Step [280/1491], Loss: 143.0227\n",
      "Epoch [1/100], Step [290/1491], Loss: 120.7780\n",
      "Epoch [1/100], Step [300/1491], Loss: 134.4299\n",
      "Epoch [1/100], Step [310/1491], Loss: 137.1352\n",
      "Epoch [1/100], Step [320/1491], Loss: 143.6606\n",
      "Epoch [1/100], Step [330/1491], Loss: 137.4525\n",
      "Epoch [1/100], Step [340/1491], Loss: 134.3165\n",
      "Epoch [1/100], Step [350/1491], Loss: 115.6027\n",
      "Epoch [1/100], Step [360/1491], Loss: 131.7021\n",
      "Epoch [1/100], Step [370/1491], Loss: 129.2280\n",
      "Epoch [1/100], Step [380/1491], Loss: 126.2001\n",
      "Epoch [1/100], Step [390/1491], Loss: 112.1271\n",
      "Epoch [1/100], Step [400/1491], Loss: 131.2948\n",
      "Epoch [1/100], Step [410/1491], Loss: 153.7678\n",
      "Epoch [1/100], Step [420/1491], Loss: 139.0938\n",
      "Epoch [1/100], Step [430/1491], Loss: 101.1834\n",
      "Epoch [1/100], Step [440/1491], Loss: 135.3654\n",
      "Epoch [1/100], Step [450/1491], Loss: 130.0396\n",
      "Epoch [1/100], Step [460/1491], Loss: 149.5899\n",
      "Epoch [1/100], Step [470/1491], Loss: 131.4122\n",
      "Epoch [1/100], Step [480/1491], Loss: 113.0252\n",
      "Epoch [1/100], Step [490/1491], Loss: 129.5138\n",
      "Epoch [1/100], Step [500/1491], Loss: 106.9777\n",
      "Epoch [1/100], Step [510/1491], Loss: 133.4954\n",
      "Epoch [1/100], Step [520/1491], Loss: 121.7363\n",
      "Epoch [1/100], Step [530/1491], Loss: 134.8413\n",
      "Epoch [1/100], Step [540/1491], Loss: 121.1024\n",
      "Epoch [1/100], Step [550/1491], Loss: 112.1307\n",
      "Epoch [1/100], Step [560/1491], Loss: 131.5298\n",
      "Epoch [1/100], Step [570/1491], Loss: 135.1134\n",
      "Epoch [1/100], Step [580/1491], Loss: 127.8367\n",
      "Epoch [1/100], Step [590/1491], Loss: 124.4945\n",
      "Epoch [1/100], Step [600/1491], Loss: 110.9220\n",
      "Epoch [1/100], Step [610/1491], Loss: 130.1935\n",
      "Epoch [1/100], Step [620/1491], Loss: 138.0242\n",
      "Epoch [1/100], Step [630/1491], Loss: 151.5765\n",
      "Epoch [1/100], Step [640/1491], Loss: 137.8379\n",
      "Epoch [1/100], Step [650/1491], Loss: 124.3052\n",
      "Epoch [1/100], Step [660/1491], Loss: 125.9056\n",
      "Epoch [1/100], Step [670/1491], Loss: 128.8883\n",
      "Epoch [1/100], Step [680/1491], Loss: 125.1190\n",
      "Epoch [1/100], Step [690/1491], Loss: 133.6408\n",
      "Epoch [1/100], Step [700/1491], Loss: 115.7142\n",
      "Epoch [1/100], Step [710/1491], Loss: 143.5300\n",
      "Epoch [1/100], Step [720/1491], Loss: 119.5856\n",
      "Epoch [1/100], Step [730/1491], Loss: 128.0776\n",
      "Epoch [1/100], Step [740/1491], Loss: 136.4549\n",
      "Epoch [1/100], Step [750/1491], Loss: 144.6044\n",
      "Epoch [1/100], Step [760/1491], Loss: 152.6179\n",
      "Epoch [1/100], Step [770/1491], Loss: 131.6322\n",
      "Epoch [1/100], Step [780/1491], Loss: 137.5321\n",
      "Epoch [1/100], Step [790/1491], Loss: 122.7431\n",
      "Epoch [1/100], Step [800/1491], Loss: 113.9958\n",
      "Epoch [1/100], Step [810/1491], Loss: 121.1825\n",
      "Epoch [1/100], Step [820/1491], Loss: 119.5366\n",
      "Epoch [1/100], Step [830/1491], Loss: 137.0336\n",
      "Epoch [1/100], Step [840/1491], Loss: 116.5560\n",
      "Epoch [1/100], Step [850/1491], Loss: 102.5969\n",
      "Epoch [1/100], Step [860/1491], Loss: 133.8272\n",
      "Epoch [1/100], Step [870/1491], Loss: 101.9776\n",
      "Epoch [1/100], Step [880/1491], Loss: 119.4354\n",
      "Epoch [1/100], Step [890/1491], Loss: 127.2975\n",
      "Epoch [1/100], Step [900/1491], Loss: 120.9990\n",
      "Epoch [1/100], Step [910/1491], Loss: 91.9401\n",
      "Epoch [1/100], Step [920/1491], Loss: 126.9846\n",
      "Epoch [1/100], Step [930/1491], Loss: 158.7800\n",
      "Epoch [1/100], Step [940/1491], Loss: 117.4379\n",
      "Epoch [1/100], Step [950/1491], Loss: 108.0238\n",
      "Epoch [1/100], Step [960/1491], Loss: 133.9283\n",
      "Epoch [1/100], Step [970/1491], Loss: 114.2559\n",
      "Epoch [1/100], Step [980/1491], Loss: 145.7635\n",
      "Epoch [1/100], Step [990/1491], Loss: 132.7479\n",
      "Epoch [1/100], Step [1000/1491], Loss: 133.4239\n",
      "Epoch [1/100], Step [1010/1491], Loss: 161.2969\n",
      "Epoch [1/100], Step [1020/1491], Loss: 156.6206\n",
      "Epoch [1/100], Step [1030/1491], Loss: 112.8177\n",
      "Epoch [1/100], Step [1040/1491], Loss: 117.9384\n",
      "Epoch [1/100], Step [1050/1491], Loss: 115.6937\n",
      "Epoch [1/100], Step [1060/1491], Loss: 107.6348\n",
      "Epoch [1/100], Step [1070/1491], Loss: 138.7813\n",
      "Epoch [1/100], Step [1080/1491], Loss: 114.1761\n",
      "Epoch [1/100], Step [1090/1491], Loss: 107.6429\n",
      "Epoch [1/100], Step [1100/1491], Loss: 110.9404\n",
      "Epoch [1/100], Step [1110/1491], Loss: 121.5985\n",
      "Epoch [1/100], Step [1120/1491], Loss: 108.2452\n",
      "Epoch [1/100], Step [1130/1491], Loss: 130.7473\n",
      "Epoch [1/100], Step [1140/1491], Loss: 121.6313\n",
      "Epoch [1/100], Step [1150/1491], Loss: 135.7518\n",
      "Epoch [1/100], Step [1160/1491], Loss: 119.0918\n",
      "Epoch [1/100], Step [1170/1491], Loss: 139.2801\n",
      "Epoch [1/100], Step [1180/1491], Loss: 113.7095\n",
      "Epoch [1/100], Step [1190/1491], Loss: 114.8024\n",
      "Epoch [1/100], Step [1200/1491], Loss: 103.7257\n",
      "Epoch [1/100], Step [1210/1491], Loss: 122.5404\n",
      "Epoch [1/100], Step [1220/1491], Loss: 132.5547\n",
      "Epoch [1/100], Step [1230/1491], Loss: 111.2777\n",
      "Epoch [1/100], Step [1240/1491], Loss: 120.3968\n",
      "Epoch [1/100], Step [1250/1491], Loss: 102.7240\n",
      "Epoch [1/100], Step [1260/1491], Loss: 121.3023\n",
      "Epoch [1/100], Step [1270/1491], Loss: 123.8599\n",
      "Epoch [1/100], Step [1280/1491], Loss: 131.6493\n",
      "Epoch [1/100], Step [1290/1491], Loss: 125.6847\n",
      "Epoch [1/100], Step [1300/1491], Loss: 137.9888\n",
      "Epoch [1/100], Step [1310/1491], Loss: 121.1294\n",
      "Epoch [1/100], Step [1320/1491], Loss: 133.9677\n",
      "Epoch [1/100], Step [1330/1491], Loss: 137.5302\n",
      "Epoch [1/100], Step [1340/1491], Loss: 156.9638\n",
      "Epoch [1/100], Step [1350/1491], Loss: 124.0411\n",
      "Epoch [1/100], Step [1360/1491], Loss: 120.8619\n",
      "Epoch [1/100], Step [1370/1491], Loss: 116.5323\n",
      "Epoch [1/100], Step [1380/1491], Loss: 134.6434\n",
      "Epoch [1/100], Step [1390/1491], Loss: 131.7614\n",
      "Epoch [1/100], Step [1400/1491], Loss: 120.9992\n",
      "Epoch [1/100], Step [1410/1491], Loss: 127.1221\n",
      "Epoch [1/100], Step [1420/1491], Loss: 110.6050\n",
      "Epoch [1/100], Step [1430/1491], Loss: 157.3795\n",
      "Epoch [1/100], Step [1440/1491], Loss: 112.7544\n",
      "Epoch [1/100], Step [1450/1491], Loss: 150.7921\n",
      "Epoch [1/100], Step [1460/1491], Loss: 119.0201\n",
      "Epoch [1/100], Step [1470/1491], Loss: 131.1209\n",
      "Epoch [1/100], Step [1480/1491], Loss: 133.0602\n",
      "Epoch [1/100], Step [1490/1491], Loss: 114.8686\n",
      "Epoch [1/100], Loss: 126.6796, Accuracy: 0.2607\n",
      "Epoch [2/100], Step [10/1491], Loss: 115.3677\n",
      "Epoch [2/100], Step [20/1491], Loss: 132.9240\n",
      "Epoch [2/100], Step [30/1491], Loss: 110.4380\n",
      "Epoch [2/100], Step [40/1491], Loss: 129.3920\n",
      "Epoch [2/100], Step [50/1491], Loss: 126.9290\n",
      "Epoch [2/100], Step [60/1491], Loss: 131.0419\n",
      "Epoch [2/100], Step [70/1491], Loss: 115.5953\n",
      "Epoch [2/100], Step [80/1491], Loss: 115.4149\n",
      "Epoch [2/100], Step [90/1491], Loss: 130.3302\n",
      "Epoch [2/100], Step [100/1491], Loss: 140.6587\n",
      "Epoch [2/100], Step [110/1491], Loss: 102.3875\n",
      "Epoch [2/100], Step [120/1491], Loss: 132.4303\n",
      "Epoch [2/100], Step [130/1491], Loss: 140.0054\n",
      "Epoch [2/100], Step [140/1491], Loss: 106.1325\n",
      "Epoch [2/100], Step [150/1491], Loss: 125.8232\n",
      "Epoch [2/100], Step [160/1491], Loss: 140.4795\n",
      "Epoch [2/100], Step [170/1491], Loss: 147.1022\n",
      "Epoch [2/100], Step [180/1491], Loss: 129.8713\n",
      "Epoch [2/100], Step [190/1491], Loss: 147.4169\n",
      "Epoch [2/100], Step [200/1491], Loss: 144.5323\n",
      "Epoch [2/100], Step [210/1491], Loss: 126.5912\n",
      "Epoch [2/100], Step [220/1491], Loss: 123.5756\n",
      "Epoch [2/100], Step [230/1491], Loss: 130.3344\n",
      "Epoch [2/100], Step [240/1491], Loss: 138.6381\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100], Step [250/1491], Loss: 122.6092\n",
      "Epoch [2/100], Step [260/1491], Loss: 132.4609\n",
      "Epoch [2/100], Step [270/1491], Loss: 108.2197\n",
      "Epoch [2/100], Step [280/1491], Loss: 120.4148\n",
      "Epoch [2/100], Step [290/1491], Loss: 134.2198\n",
      "Epoch [2/100], Step [300/1491], Loss: 141.4025\n",
      "Epoch [2/100], Step [310/1491], Loss: 114.5742\n",
      "Epoch [2/100], Step [320/1491], Loss: 172.1622\n",
      "Epoch [2/100], Step [330/1491], Loss: 138.3727\n",
      "Epoch [2/100], Step [340/1491], Loss: 141.2471\n",
      "Epoch [2/100], Step [350/1491], Loss: 135.9932\n",
      "Epoch [2/100], Step [360/1491], Loss: 143.6316\n",
      "Epoch [2/100], Step [370/1491], Loss: 140.0350\n",
      "Epoch [2/100], Step [380/1491], Loss: 103.4232\n",
      "Epoch [2/100], Step [390/1491], Loss: 144.6303\n",
      "Epoch [2/100], Step [430/1491], Loss: 128.0889\n",
      "Epoch [2/100], Step [440/1491], Loss: 151.8863\n",
      "Epoch [2/100], Step [450/1491], Loss: 108.5473\n",
      "Epoch [2/100], Step [460/1491], Loss: 126.8167\n",
      "Epoch [2/100], Step [470/1491], Loss: 135.9303\n",
      "Epoch [2/100], Step [480/1491], Loss: 125.4854\n",
      "Epoch [2/100], Step [490/1491], Loss: 123.3883\n",
      "Epoch [2/100], Step [500/1491], Loss: 117.0896\n",
      "Epoch [2/100], Step [510/1491], Loss: 110.5178\n",
      "Epoch [2/100], Step [520/1491], Loss: 124.4214\n",
      "Epoch [2/100], Step [530/1491], Loss: 144.4375\n",
      "Epoch [2/100], Step [540/1491], Loss: 115.5172\n",
      "Epoch [2/100], Step [550/1491], Loss: 120.8463\n",
      "Epoch [2/100], Step [560/1491], Loss: 127.6698\n",
      "Epoch [2/100], Step [570/1491], Loss: 123.4746\n",
      "Epoch [2/100], Step [580/1491], Loss: 121.1098\n",
      "Epoch [2/100], Step [590/1491], Loss: 118.8274\n",
      "Epoch [2/100], Step [600/1491], Loss: 155.2357\n",
      "Epoch [2/100], Step [610/1491], Loss: 130.3814\n",
      "Epoch [2/100], Step [620/1491], Loss: 144.1624\n",
      "Epoch [2/100], Step [630/1491], Loss: 102.0373\n",
      "Epoch [2/100], Step [640/1491], Loss: 102.6639\n",
      "Epoch [2/100], Step [650/1491], Loss: 113.9266\n",
      "Epoch [2/100], Step [660/1491], Loss: 106.2310\n",
      "Epoch [2/100], Step [670/1491], Loss: 106.8326\n",
      "Epoch [2/100], Step [680/1491], Loss: 142.4175\n",
      "Epoch [2/100], Step [690/1491], Loss: 136.1870\n",
      "Epoch [2/100], Step [700/1491], Loss: 111.7249\n",
      "Epoch [2/100], Step [710/1491], Loss: 119.7593\n",
      "Epoch [2/100], Step [720/1491], Loss: 103.9944\n",
      "Epoch [2/100], Step [730/1491], Loss: 107.2936\n",
      "Epoch [2/100], Step [740/1491], Loss: 137.0091\n",
      "Epoch [2/100], Step [750/1491], Loss: 130.5169\n",
      "Epoch [2/100], Step [760/1491], Loss: 123.8139\n",
      "Epoch [2/100], Step [770/1491], Loss: 154.5407\n",
      "Epoch [2/100], Step [780/1491], Loss: 127.9674\n",
      "Epoch [2/100], Step [790/1491], Loss: 115.9121\n",
      "Epoch [2/100], Step [800/1491], Loss: 131.0042\n",
      "Epoch [2/100], Step [810/1491], Loss: 130.9850\n",
      "Epoch [2/100], Step [820/1491], Loss: 120.6473\n",
      "Epoch [2/100], Step [830/1491], Loss: 123.6680\n",
      "Epoch [2/100], Step [840/1491], Loss: 139.5919\n",
      "Epoch [2/100], Step [850/1491], Loss: 117.5628\n",
      "Epoch [2/100], Step [860/1491], Loss: 135.9527\n",
      "Epoch [2/100], Step [870/1491], Loss: 125.7500\n",
      "Epoch [2/100], Step [880/1491], Loss: 126.9008\n",
      "Epoch [2/100], Step [890/1491], Loss: 127.6744\n",
      "Epoch [2/100], Step [900/1491], Loss: 133.8312\n",
      "Epoch [2/100], Step [910/1491], Loss: 95.3416\n",
      "Epoch [2/100], Step [920/1491], Loss: 110.3499\n",
      "Epoch [2/100], Step [930/1491], Loss: 134.5972\n",
      "Epoch [2/100], Step [940/1491], Loss: 111.2635\n",
      "Epoch [2/100], Step [950/1491], Loss: 122.1460\n",
      "Epoch [2/100], Step [960/1491], Loss: 128.8945\n",
      "Epoch [2/100], Step [970/1491], Loss: 126.1698\n",
      "Epoch [2/100], Step [980/1491], Loss: 111.4243\n",
      "Epoch [2/100], Step [990/1491], Loss: 110.9699\n",
      "Epoch [2/100], Step [1000/1491], Loss: 107.5985\n",
      "Epoch [2/100], Step [1010/1491], Loss: 105.4947\n",
      "Epoch [2/100], Step [1020/1491], Loss: 114.0822\n",
      "Epoch [2/100], Step [1030/1491], Loss: 125.7881\n",
      "Epoch [2/100], Step [1040/1491], Loss: 135.9685\n",
      "Epoch [2/100], Step [1050/1491], Loss: 125.1342\n",
      "Epoch [2/100], Step [1060/1491], Loss: 130.2305\n",
      "Epoch [2/100], Step [1070/1491], Loss: 140.2674\n",
      "Epoch [2/100], Step [1080/1491], Loss: 131.0317\n",
      "Epoch [2/100], Step [1090/1491], Loss: 124.9233\n",
      "Epoch [2/100], Step [1100/1491], Loss: 108.8557\n",
      "Epoch [2/100], Step [1110/1491], Loss: 99.7590\n",
      "Epoch [2/100], Step [1120/1491], Loss: 97.8531\n",
      "Epoch [2/100], Step [1130/1491], Loss: 141.6730\n",
      "Epoch [2/100], Step [1140/1491], Loss: 127.0392\n",
      "Epoch [2/100], Step [1150/1491], Loss: 127.9897\n",
      "Epoch [2/100], Step [1160/1491], Loss: 146.9183\n",
      "Epoch [2/100], Step [1170/1491], Loss: 107.7823\n",
      "Epoch [2/100], Step [1180/1491], Loss: 112.6906\n",
      "Epoch [2/100], Step [1190/1491], Loss: 91.5822\n",
      "Epoch [2/100], Step [1200/1491], Loss: 118.4711\n",
      "Epoch [2/100], Step [1210/1491], Loss: 121.9916\n",
      "Epoch [2/100], Step [1220/1491], Loss: 110.2728\n",
      "Epoch [2/100], Step [1230/1491], Loss: 125.4531\n",
      "Epoch [2/100], Step [1240/1491], Loss: 122.5278\n",
      "Epoch [2/100], Step [1250/1491], Loss: 110.9242\n",
      "Epoch [2/100], Step [1260/1491], Loss: 127.7646\n",
      "Epoch [2/100], Step [1270/1491], Loss: 131.3315\n",
      "Epoch [2/100], Step [1280/1491], Loss: 108.9742\n",
      "Epoch [2/100], Step [1290/1491], Loss: 118.1661\n",
      "Epoch [2/100], Step [1300/1491], Loss: 131.2161\n",
      "Epoch [2/100], Step [1310/1491], Loss: 140.4447\n",
      "Epoch [2/100], Step [1320/1491], Loss: 121.5052\n",
      "Epoch [2/100], Step [1330/1491], Loss: 135.8191\n",
      "Epoch [2/100], Step [1340/1491], Loss: 137.7642\n",
      "Epoch [2/100], Step [1350/1491], Loss: 116.9981\n",
      "Epoch [2/100], Step [1360/1491], Loss: 132.9229\n",
      "Epoch [2/100], Step [1370/1491], Loss: 123.3705\n",
      "Epoch [2/100], Step [1380/1491], Loss: 112.4686\n",
      "Epoch [2/100], Step [1390/1491], Loss: 137.9777\n",
      "Epoch [2/100], Step [1400/1491], Loss: 105.9683\n",
      "Epoch [2/100], Step [1410/1491], Loss: 136.8247\n",
      "Epoch [2/100], Step [1420/1491], Loss: 130.8185\n",
      "Epoch [2/100], Step [1430/1491], Loss: 105.7808\n",
      "Epoch [2/100], Step [1440/1491], Loss: 120.2444\n",
      "Epoch [2/100], Step [1450/1491], Loss: 152.2303\n",
      "Epoch [2/100], Step [1460/1491], Loss: 118.3567\n",
      "Epoch [2/100], Step [1470/1491], Loss: 112.2212\n",
      "Epoch [2/100], Step [1480/1491], Loss: 121.7122\n",
      "Epoch [2/100], Step [1490/1491], Loss: 127.3597\n",
      "Epoch [2/100], Loss: 124.5208, Accuracy: 0.0003\n",
      "Epoch [3/100], Step [10/1491], Loss: 124.2566\n",
      "Epoch [3/100], Step [20/1491], Loss: 127.1591\n",
      "Epoch [3/100], Step [30/1491], Loss: 129.9318\n",
      "Epoch [3/100], Step [40/1491], Loss: 142.8768\n",
      "Epoch [3/100], Step [50/1491], Loss: 133.6995\n",
      "Epoch [3/100], Step [60/1491], Loss: 102.0206\n",
      "Epoch [3/100], Step [70/1491], Loss: 93.9733\n",
      "Epoch [3/100], Step [80/1491], Loss: 134.8650\n",
      "Epoch [3/100], Step [90/1491], Loss: 111.5939\n",
      "Epoch [3/100], Step [100/1491], Loss: 106.7204\n",
      "Epoch [3/100], Step [110/1491], Loss: 154.8817\n",
      "Epoch [3/100], Step [120/1491], Loss: 154.5936\n",
      "Epoch [3/100], Step [130/1491], Loss: 161.1928\n",
      "Epoch [3/100], Step [140/1491], Loss: 161.0825\n",
      "Epoch [3/100], Step [150/1491], Loss: 139.6660\n",
      "Epoch [3/100], Step [160/1491], Loss: 147.9482\n",
      "Epoch [3/100], Step [170/1491], Loss: 116.2945\n",
      "Epoch [3/100], Step [180/1491], Loss: 132.9546\n",
      "Epoch [3/100], Step [190/1491], Loss: 130.1712\n",
      "Epoch [3/100], Step [200/1491], Loss: 108.1133\n",
      "Epoch [3/100], Step [210/1491], Loss: 103.9649\n",
      "Epoch [3/100], Step [220/1491], Loss: 130.5528\n",
      "Epoch [3/100], Step [230/1491], Loss: 117.6387\n",
      "Epoch [3/100], Step [240/1491], Loss: 118.6958\n",
      "Epoch [3/100], Step [250/1491], Loss: 104.2170\n",
      "Epoch [3/100], Step [260/1491], Loss: 130.3306\n",
      "Epoch [3/100], Step [270/1491], Loss: 115.1531\n",
      "Epoch [3/100], Step [280/1491], Loss: 142.9683\n",
      "Epoch [3/100], Step [290/1491], Loss: 113.8372\n",
      "Epoch [3/100], Step [300/1491], Loss: 105.0932\n",
      "Epoch [3/100], Step [310/1491], Loss: 117.5692\n",
      "Epoch [3/100], Step [320/1491], Loss: 116.8940\n",
      "Epoch [3/100], Step [330/1491], Loss: 124.0695\n",
      "Epoch [3/100], Step [340/1491], Loss: 120.6598\n",
      "Epoch [3/100], Step [350/1491], Loss: 102.1240\n",
      "Epoch [3/100], Step [390/1491], Loss: 128.2769\n",
      "Epoch [3/100], Step [400/1491], Loss: 134.9266\n",
      "Epoch [3/100], Step [410/1491], Loss: 123.3877\n",
      "Epoch [3/100], Step [420/1491], Loss: 135.7243\n",
      "Epoch [3/100], Step [430/1491], Loss: 94.2318\n",
      "Epoch [3/100], Step [440/1491], Loss: 95.7009\n",
      "Epoch [3/100], Step [450/1491], Loss: 108.0955\n",
      "Epoch [3/100], Step [460/1491], Loss: 132.5770\n",
      "Epoch [3/100], Step [470/1491], Loss: 105.4370\n",
      "Epoch [3/100], Step [480/1491], Loss: 125.8081\n",
      "Epoch [3/100], Step [490/1491], Loss: 120.6828\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m     torch\u001b[38;5;241m.\u001b[39msave(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./model/Speech2Text.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (audio, text) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[0;32m---> 10\u001b[0m     audio \u001b[38;5;241m=\u001b[39m \u001b[43maudio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     text \u001b[38;5;241m=\u001b[39m text\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(audio)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    total_correct = 0\n",
    "    \n",
    "    if (epoch + 1) % 2 == 0:\n",
    "        torch.save(model, \"./model/Speech2Text.pt\")\n",
    "\n",
    "    for i, (audio, text) in enumerate(dataloader):\n",
    "        audio = audio.to(device)\n",
    "        text = text.to(device)\n",
    "\n",
    "        outputs = model(audio)\n",
    "#         print(outputs.dtype)\n",
    "#         print(text.dtype)\n",
    "\n",
    "        loss = criterion(outputs, text)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        text = text.view(-1, 1)\n",
    "        total_correct += (predicted == text).sum().item()\n",
    "\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{total_step}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    epoch_loss = total_loss / total_step\n",
    "    epoch_acc = total_correct / (batch_size * total_step)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, input_file):\n",
    "    model.eval()  # 모델을 평가 모드로 설정\n",
    "    \n",
    "    audio, _ = torchaudio.load(input_file)  \n",
    "    audio = audio.unsqueeze(0).to(device) \n",
    "\n",
    "    output = model(audio) \n",
    "\n",
    "    return output.int().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = predict(model,'./wav_all_stereo(fixed_length)/SDRW2000000414.1.1.18.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse = dict(map(reversed,lookup.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = []\n",
    "for i in range(len(output[0])):\n",
    "    out.append(reverse[output[0,i].item()])\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
